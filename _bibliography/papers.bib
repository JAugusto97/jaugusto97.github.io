---
---
@inproceedings{leite-etal-2020-toxic,
    abbr = {AACL},
    title = "Toxic Language Detection in Social Media for {B}razilian {P}ortuguese: New Dataset and Multilingual Analysis",
    author = "Leite, Jo{\~a}o A.  and
      Silva, Diego  and
      Bontcheva, Kalina  and
      Scarton, Carolina",
    editor = "Wong, Kam-Fai  and
      Knight, Kevin  and
      Wu, Hua",
    booktitle = "Proceedings of the 1st Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 10th International Joint Conference on Natural Language Processing",
    month = dec,
    year = "2020",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.aacl-main.91",
    html = {https://aclanthology.org/2020.aacl-main.91},
    pages = "914--924",
    abstract = "Hate speech and toxic comments are a common concern of social media platform users. Although these comments are, fortunately, the minority in these platforms, they are still capable of causing harm. Therefore, identifying these comments is an important task for studying and preventing the proliferation of toxicity in social media. Previous work in automatically detecting toxic comments focus mainly in English, with very few work in languages like Brazilian Portuguese. In this paper, we propose a new large-scale dataset for Brazilian Portuguese with tweets annotated as either toxic or non-toxic or in different types of toxicity. We present our dataset collection and annotation process, where we aimed to select candidates covering multiple demographic groups. State-of-the-art BERT models were able to achieve 76{\%} macro-F1 score using monolingual data in the binary case. We also show that large-scale monolingual data is still needed to create more accurate models, despite recent advances in multilingual approaches. An error analysis and experiments with multi-label classification show the difficulty of classifying certain types of toxic comments that appear less frequently in our data and highlights the need to develop models that are aware of different categories of toxicity.",
    selected = {true},
    google_scholar_id = {u-x6o8ySG0sC},
    pdf = {toxic_2020.pdf},
    dimensions = {true},
}

@misc{leite2024weaklysupervisedveracityclassification,
      abbr = {arXiv},
      title={Weakly Supervised Veracity Classification with LLM-Predicted Credibility Signals}, 
      author={João A. Leite and Olesya Razuvayevskaya and Kalina Bontcheva and Carolina Scarton},
      year={2024},
      month={10},
      eprint={2309.07601},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.07601}, 
      selected = {true},
      google_scholar_id = {Tyk-4Ss8FVUC},
      pdf = {pastel.pdf},
      html = {https://arxiv.org/abs/2309.07601},
}

@inproceedings{10.1145/3627673.3679167,
abbr = {CIKM},
author = {Leite, Jo\~{a}o A. and Razuvayevskaya, Olesya and Bontcheva, Kalina and Scarton, Carolina},
title = {EUvsDisinfo: A Dataset for Multilingual Detection of Pro-Kremlin Disinformation in News Articles},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679167},
doi = {10.1145/3627673.3679167},
abstract = {This work introduces EUvsDisinfo, a multilingual dataset of disinformation articles originating from pro-Kremlin outlets, along with trustworthy articles from credible / less biased sources. It is sourced directly from the debunk articles written by experts leading the EUvsDisinfo project. Our dataset is the largest to-date resource in terms of the overall number of articles and distinct languages. It also provides the largest topical and temporal coverage. Using this dataset, we investigate the dissemination of pro-Kremlin disinformation across different languages, uncovering language-specific patterns targeting certain disinformation topics. We further analyse the evolution of topic distribution over an eight-year period, noting a significant surge in disinformation content before the full-scale invasion of Ukraine in 2022. Lastly, we demonstrate the dataset's applicability in training models to effectively distinguish between disinformation and trustworthy content in multilingual settings.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5380–5384},
numpages = {5},
keywords = {classification, dataset, disinformation, news articles, pro-kremlin},
location = {Boise, ID, USA},
series = {CIKM '24},
selected = {true},
google_scholar_id = {YsMSGLbcyi4C},
pdf = {euvdisinfo_cikm.pdf},
}

@article{leite2024cross,
  abbr = {WWW},
  title={A Cross-Domain Study of the Use of Persuasion Techniques in Online Disinformation},
  author={Leite, Jo{\~a}o A and Razuvayevskaya, Olesya and Scarton, Carolina and Bontcheva, Kalina},
  year={2024},
  month={12},
  eprint={2412.15098},
  archivePrefix={arXiv},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2412.15098},
  selected = {true},
  google_scholar_id = {Se3iqnhoufwC},
  pdf = {euvdisinfo_cikm.pdf},
}

@article{olesya-2024-comparison,
    abbr = {PLOS ONE},
    doi = {10.1371/journal.pone.0301738},
    author = {Razuvayevskaya, Olesya AND Wu, Ben AND Leite, João A. AND Heppell, Freddy AND Srba, Ivan AND Scarton, Carolina AND Bontcheva, Kalina AND Song, Xingyi},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Comparison between parameter-efficient techniques and full fine-tuning: A case study on multilingual news article classification},
    year = {2024},
    month = {05},
    volume = {19},
    url = {https://doi.org/10.1371/journal.pone.0301738},
    pages = {1-26},
    abstract = {Adapters and Low-Rank Adaptation (LoRA) are parameter-efficient fine-tuning techniques designed to make the training of language models more efficient. Previous results demonstrated that these methods can even improve performance on some classification tasks. This paper complements existing research by investigating how these techniques influence classification performance and computation costs compared to full fine-tuning. We focus specifically on multilingual text classification tasks (genre, framing, and persuasion techniques detection; with different input lengths, number of predicted classes and classification difficulty), some of which have limited training data. In addition, we conduct in-depth analyses of their efficacy across different training scenarios (training on the original multilingual data; on the translations into English; and on a subset of English-only data) and different languages. Our findings provide valuable insights into the applicability of parameter-efficient fine-tuning techniques, particularly for multilabel classification and non-parallel multilingual tasks which are aimed at analysing input texts of varying length.},
    number = {5},
    selected = {false},
    google_scholar_id = {zYLM7Y9cAGgC},
    pdf = {comparison-plos.pdf},
}

@article{srba2024survey,
  title={A Survey on Automatic Credibility Assessment of Textual Credibility Signals in the Era of Large Language Models},
  author={Srba, Ivan and Razuvayevskaya, Olesya and Leite, Jo{\~a}o A and Moro, Robert and Schlicht, Ipek Baris and Tonelli, Sara and Garc{\'\i}a, Francisco Moreno and Lottmann, Santiago Barrio and Teyssou, Denis and Porcellini, Valentin and others},
  year={2024},
  month={10},
  abbr = {arXiv},
  archivePrefix={arXiv},
  eprint={2410.21360},
  primaryClass={cs.CL},
  url={https://arxiv.org/abs/2410.21360},
  selected = {false},
  google_scholar_id = {roLk4NBRz8UC},
}